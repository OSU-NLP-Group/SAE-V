<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.1">
<title>saev.activations API documentation</title>
<meta name="description" content="To save lots of activations, we want to do things in parallel, with lots of slurm jobs, and save multiple files, rather than just one …">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>saev.activations</code></h1>
</header>
<section id="section-intro">
<p>To save lots of activations, we want to do things in parallel, with lots of slurm jobs, and save multiple files, rather than just one.</p>
<p>This module handles that additional complexity.</p>
<p>Conceptually, activations are either thought of as</p>
<ol>
<li>A single [n_imgs x n_layers x (n_patches + 1), d_vit] tensor. This is a <em>dataset</em></li>
<li>Multiple [n_imgs_per_shard, n_layers, (n_patches + 1), d_vit] tensors. This is a set of sharded activations.</li>
</ol>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="saev.activations.dump"><code class="name flex">
<span>def <span class="ident">dump</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong></dt>
<dd>Config for activations.</dd>
</dl></div>
</dd>
<dt id="saev.activations.get_acts_dir"><code class="name flex">
<span>def <span class="ident">get_acts_dir</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Return the activations filepath based on the relevant values of a config.
Also saves a metadata.json file to that directory for human reference.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong></dt>
<dd>Config for experiment.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Directory to where activations should be dumped/loaded from.</p></div>
</dd>
<dt id="saev.activations.get_broden_dataloader"><code class="name flex">
<span>def <span class="ident">get_broden_dataloader</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>, preprocess) ‑> torch.utils.data.dataloader.DataLoader</span>
</code></dt>
<dd>
<div class="desc"><p>Get a dataloader for Broden dataset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong></dt>
<dd>Config.</dd>
<dt><strong><code>preprocess</code></strong></dt>
<dd>Image transform to be applied to each image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A PyTorch Dataloader that yields dictionaries with <code>'image'</code> keys containing image batches and <code>'index'</code> keys containing original dataset indices.</p></div>
</dd>
<dt id="saev.activations.get_dataloader"><code class="name flex">
<span>def <span class="ident">get_dataloader</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>, preprocess)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the dataloader for the current experiment; delegates dataloader construction to dataset-specific functions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong></dt>
<dd>Experiment config.</dd>
<dt><strong><code>preprocess</code></strong></dt>
<dd>Image transform to be applied to each image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A PyTorch Dataloader that yields dictionaries with <code>'image'</code> keys containing image batches.</p></div>
</dd>
<dt id="saev.activations.get_imagefolder_dataloader"><code class="name flex">
<span>def <span class="ident">get_imagefolder_dataloader</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>, preprocess) ‑> torch.utils.data.dataloader.DataLoader</span>
</code></dt>
<dd>
<div class="desc"><p>Get a dataloader for an ImageFolder.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong></dt>
<dd>Config.</dd>
<dt><strong><code>preprocess</code></strong></dt>
<dd>Image transform to be applied to each image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A PyTorch Dataloader that yields dictionaries with <code>'image'</code> keys containing image batches, <code>'index'</code> keys containing original dataset indices and <code>'label'</code> keys containing label batches.</p></div>
</dd>
<dt id="saev.activations.get_imagenet_dataloader"><code class="name flex">
<span>def <span class="ident">get_imagenet_dataloader</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>, preprocess) ‑> torch.utils.data.dataloader.DataLoader</span>
</code></dt>
<dd>
<div class="desc"><p>Get a dataloader for Imagenet loaded from Huggingface.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong></dt>
<dd>Config.</dd>
<dt><strong><code>preprocess</code></strong></dt>
<dd>Image transform to be applied to each image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A PyTorch Dataloader that yields dictionaries with <code>'image'</code> keys containing image batches, <code>'index'</code> keys containing original dataset indices and <code>'label'</code> keys containing label batches.</p></div>
</dd>
<dt id="saev.activations.get_laion_dataloader"><code class="name flex">
<span>def <span class="ident">get_laion_dataloader</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>, preprocess) ‑> torch.utils.data.dataloader.DataLoader</span>
</code></dt>
<dd>
<div class="desc"><p>Get a dataloader for a subset of the LAION datasets.</p>
<p>This requires several steps:</p>
<ol>
<li>Download list of image URLs</li>
<li>Use img2dataset to download these images to webdataset format.</li>
<li>Create a dataloader from these webdataset tar files.</li>
</ol>
<p>So that we don't have to redo any of these steps, we check on the existence of various files to check if this stuff is done already.</p></div>
</dd>
<dt id="saev.activations.get_tol_dataloader"><code class="name flex">
<span>def <span class="ident">get_tol_dataloader</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>, preprocess) ‑> torch.utils.data.dataloader.DataLoader</span>
</code></dt>
<dd>
<div class="desc"><p>Get a dataloader for the TreeOfLife-10M dataset.</p>
<p>Currently does not include a true index or label in the loaded examples.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong></dt>
<dd>Config for loading activations.</dd>
<dt><strong><code>preprocess</code></strong></dt>
<dd>Image transform to be applied to each image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A PyTorch Dataloader that yields dictionaries with <code>'image'</code> keys containing image batches.</p></div>
</dd>
<dt id="saev.activations.make_vit"><code class="name flex">
<span>def <span class="ident">make_vit</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.setup"><code class="name flex">
<span>def <span class="ident">setup</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Run dataset-specific setup. These setup functions can assume they are the only job running, but they should be idempotent; they should be safe (and ideally cheap) to run multiple times in a row.</p></div>
</dd>
<dt id="saev.activations.setup_broden"><code class="name flex">
<span>def <span class="ident">setup_broden</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.setup_imagefolder"><code class="name flex">
<span>def <span class="ident">setup_imagefolder</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.setup_imagenet"><code class="name flex">
<span>def <span class="ident">setup_imagenet</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.setup_laion"><code class="name flex">
<span>def <span class="ident">setup_laion</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Do setup for LAION dataloader.</p></div>
</dd>
<dt id="saev.activations.setup_tol"><code class="name flex">
<span>def <span class="ident">setup_tol</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.worker_fn"><code class="name flex">
<span>def <span class="ident">worker_fn</span></span>(<span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong></dt>
<dd>Config for activations.</dd>
</dl></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="saev.activations.Clip"><code class="flex name class">
<span>class <span class="ident">Clip</span></span>
<span>(</span><span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -&gt; None:
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
class Clip(torch.nn.Module):
    def __init__(self, cfg: config.Activations):
        super().__init__()

        assert cfg.model_org == &#34;clip&#34;

        import open_clip

        if cfg.model_ckpt.startswith(&#34;hf-hub:&#34;):
            clip, self._img_transform = open_clip.create_model_from_pretrained(
                cfg.model_ckpt, cache_dir=helpers.get_cache_dir()
            )
        else:
            arch, ckpt = cfg.model_ckpt.split(&#34;/&#34;)
            clip, self._img_transform = open_clip.create_model_from_pretrained(
                arch, pretrained=ckpt, cache_dir=helpers.get_cache_dir()
            )

        model = clip.visual
        model.proj = None
        model.output_tokens = True  # type: ignore
        self.model = model

        assert not isinstance(self.model, open_clip.timm_model.TimmModel)
        self.recorder = VitRecorder(cfg).register(self.model.transformer.resblocks)

    def make_img_transform(self):
        return self._img_transform

    def forward(self, batch: Float[Tensor, &#34;batch 3 width height&#34;]):
        self.recorder.reset()
        result = self.model(batch)
        return result, self.recorder.activations</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="saev.activations.Clip.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, batch: jaxtyping.Float[Tensor, 'batch 3 width height']) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
</dd>
<dt id="saev.activations.Clip.make_img_transform"><code class="name flex">
<span>def <span class="ident">make_img_transform</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="saev.activations.Dataset"><code class="flex name class">
<span>class <span class="ident">Dataset</span></span>
<span>(</span><span>cfg: <a title="saev.config.DataLoad" href="config.html#saev.config.DataLoad">DataLoad</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Dataset of activations from disk.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
class Dataset(torch.utils.data.Dataset):
    &#34;&#34;&#34;
    Dataset of activations from disk.
    &#34;&#34;&#34;

    class Example(typing.NamedTuple):
        &#34;&#34;&#34;Individual example.&#34;&#34;&#34;

        vit_acts: Float[Tensor, &#34; d_vit&#34;]
        img_i: Int[Tensor, &#34;&#34;]
        patch_i: Int[Tensor, &#34;&#34;]

    cfg: config.DataLoad
    &#34;&#34;&#34;Configuration; set via CLI args.&#34;&#34;&#34;
    metadata: &#34;Metadata&#34;
    &#34;&#34;&#34;Activations metadata; automatically loaded from disk.&#34;&#34;&#34;
    layer_index: int
    &#34;&#34;&#34;Layer index into the shards if we are choosing a specific layer.&#34;&#34;&#34;
    scalar: float
    &#34;&#34;&#34;Normalizing scalar such that ||x / scalar ||_2 ~= sqrt(d_vit).&#34;&#34;&#34;
    act_mean: Float[Tensor, &#34; d_vit&#34;]
    &#34;&#34;&#34;Mean activation.&#34;&#34;&#34;

    def __init__(self, cfg: config.DataLoad):
        self.cfg = cfg
        if not os.path.isdir(self.cfg.shard_root):
            raise RuntimeError(f&#34;Activations are not saved at &#39;{self.cfg.shard_root}&#39;.&#34;)

        metadata_fpath = os.path.join(self.cfg.shard_root, &#34;metadata.json&#34;)
        self.metadata = Metadata.load(metadata_fpath)

        # Pick a really big number so that if you accidentally use this when you shouldn&#39;t, you get an out of bounds IndexError.
        self.layer_index = 1_000_000
        if isinstance(self.cfg.layer, int):
            err_msg = f&#34;Non-exact matches for .layer field not supported; {self.cfg.layer} not in {self.metadata.layers}.&#34;
            assert self.cfg.layer in self.metadata.layers, err_msg
            self.layer_index = self.metadata.layers.index(self.cfg.layer)

        # Premptively set these values so that preprocess() doesn&#39;t freak out.
        self.scalar = 1.0
        self.act_mean = torch.zeros(self.d_vit)

        # If neither of these are true, we can skip this work.
        if self.cfg.scale_mean or self.cfg.scale_norm:
            # Load a random subset of samples to calculate the mean activation and mean L2 norm.
            perm = np.random.default_rng(seed=42).permutation(len(self))
            perm = perm[: cfg.n_random_samples]

            samples, _, _ = zip(*[
                self[p.item()]
                for p in helpers.progress(
                    perm, every=25_000, desc=&#34;examples to calc means&#34;
                )
            ])
            samples = torch.stack(samples)
            if samples.abs().max() &gt; 1e3:
                raise ValueError(
                    &#34;You found an abnormally large activation {example.abs().max().item():.5f} that will mess up your L2 mean.&#34;
                )

            # Activation mean
            if self.cfg.scale_mean:
                self.act_mean = samples.mean(axis=0)
                if (self.act_mean &gt; 1e3).any():
                    raise ValueError(
                        &#34;You found an abnormally large activation that is messing up your activation mean.&#34;
                    )

            # Norm
            if self.cfg.scale_norm:
                l2_mean = torch.linalg.norm(samples - self.act_mean, axis=1).mean()
                if l2_mean &gt; 1e3:
                    raise ValueError(
                        &#34;You found an abnormally large activation that is messing up your L2 mean.&#34;
                    )

                self.scalar = l2_mean / math.sqrt(self.d_vit)

    def transform(self, act: Float[np.ndarray, &#34; d_vit&#34;]) -&gt; Float[Tensor, &#34; d_vit&#34;]:
        &#34;&#34;&#34;
        Apply a scalar normalization so the mean squared L2 norm is same as d_vit. This is from &#39;Scaling Monosemanticity&#39;:

        &gt; As a preprocessing step we apply a scalar normalization to the model activations so their average squared L2 norm is the residual stream dimension

        So we divide by self.scalar which is the datasets (approximate) L2 mean before normalization divided by sqrt(d_vit).
        &#34;&#34;&#34;
        act = torch.from_numpy(act.copy())
        act = act.clamp(-self.cfg.clamp, self.cfg.clamp)
        return (act - self.act_mean) / self.scalar

    @property
    def d_vit(self) -&gt; int:
        &#34;&#34;&#34;Dimension of the underlying vision transformer&#39;s embedding space.&#34;&#34;&#34;
        return self.metadata.d_vit

    @jaxtyped(typechecker=beartype.beartype)
    def __getitem__(self, i: int) -&gt; Example:
        match (self.cfg.patches, self.cfg.layer):
            case (&#34;cls&#34;, int()):
                img_act = self.get_img_patches(i)
                # Select layer&#39;s cls token.
                act = img_act[self.layer_index, 0, :]
                return self.Example(
                    self.transform(act), torch.tensor(i), torch.tensor(-1)
                )
            case (&#34;cls&#34;, &#34;meanpool&#34;):
                img_act = self.get_img_patches(i)
                # Select cls tokens from across all layers
                cls_act = img_act[:, 0, :]
                # Meanpool over the layers
                act = cls_act.mean(axis=0)
                return self.Example(
                    self.transform(act), torch.tensor(i), torch.tensor(-1)
                )
            case (&#34;meanpool&#34;, int()):
                img_act = self.get_img_patches(i)
                # Select layer&#39;s patches.
                layer_act = img_act[self.layer_index, 1:, :]
                # Meanpool over the patches
                act = layer_act.mean(axis=0)
                return self.Example(
                    self.transform(act), torch.tensor(i), torch.tensor(-1)
                )
            case (&#34;meanpool&#34;, &#34;meanpool&#34;):
                img_act = self.get_img_patches(i)
                # Select all layer&#39;s patches.
                act = img_act[:, 1:, :]
                # Meanpool over the layers and patches
                act = act.mean(axis=(0, 1))
                return self.Example(
                    self.transform(act), torch.tensor(i), torch.tensor(-1)
                )
            case (&#34;patches&#34;, int()):
                n_imgs_per_shard = (
                    self.metadata.n_patches_per_shard
                    // len(self.metadata.layers)
                    // (self.metadata.n_patches_per_img + 1)
                )
                n_examples_per_shard = (
                    n_imgs_per_shard * self.metadata.n_patches_per_img
                )

                shard = i // n_examples_per_shard
                pos = i % n_examples_per_shard

                acts_fpath = os.path.join(self.cfg.shard_root, f&#34;acts{shard:06}.bin&#34;)
                shape = (
                    n_imgs_per_shard,
                    len(self.metadata.layers),
                    self.metadata.n_patches_per_img + 1,
                    self.metadata.d_vit,
                )
                acts = np.memmap(acts_fpath, mode=&#34;c&#34;, dtype=np.float32, shape=shape)
                # Choose the layer and the non-CLS tokens.
                acts = acts[:, self.layer_index, 1:]

                # Choose a patch among n and the patches.
                act = acts[
                    pos // self.metadata.n_patches_per_img,
                    pos % self.metadata.n_patches_per_img,
                ]
                return self.Example(
                    self.transform(act),
                    # What image is this?
                    torch.tensor(i // self.metadata.n_patches_per_img),
                    torch.tensor(i % self.metadata.n_patches_per_img),
                )
            case _:
                print((self.cfg.patches, self.cfg.layer))
                typing.assert_never((self.cfg.patches, self.cfg.layer))

    def get_shard_patches(self):
        raise NotImplementedError()

    def get_img_patches(
        self, i: int
    ) -&gt; Float[np.ndarray, &#34;n_layers all_patches d_vit&#34;]:
        n_imgs_per_shard = (
            self.metadata.n_patches_per_shard
            // len(self.metadata.layers)
            // (self.metadata.n_patches_per_img + 1)
        )
        shard = i // n_imgs_per_shard
        pos = i % n_imgs_per_shard
        acts_fpath = os.path.join(self.cfg.shard_root, f&#34;acts{shard:06}.bin&#34;)
        shape = (
            n_imgs_per_shard,
            len(self.metadata.layers),
            self.metadata.n_patches_per_img + 1,
            self.metadata.d_vit,
        )
        acts = np.memmap(acts_fpath, mode=&#34;c&#34;, dtype=np.float32, shape=shape)
        # Note that this is not yet copied!
        return acts[pos]

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;
        Dataset length depends on `patches` and `layer`.
        &#34;&#34;&#34;
        match (self.cfg.patches, self.cfg.layer):
            case (&#34;cls&#34;, &#34;all&#34;):
                # Return a CLS token from a random image and random layer.
                return self.metadata.n_imgs * len(self.metadata.layers)
            case (&#34;cls&#34;, int()):
                # Return a CLS token from a random image and fixed layer.
                return self.metadata.n_imgs
            case (&#34;cls&#34;, &#34;meanpool&#34;):
                # Return a CLS token from a random image and meanpool over all layers.
                return self.metadata.n_imgs
            case (&#34;meanpool&#34;, &#34;all&#34;):
                # Return the meanpool of all patches from a random image and random layer.
                return self.metadata.n_imgs * len(self.metadata.layers)
            case (&#34;meanpool&#34;, int()):
                # Return the meanpool of all patches from a random image and fixed layer.
                return self.metadata.n_imgs
            case (&#34;meanpool&#34;, &#34;meanpool&#34;):
                # Return the meanpool of all patches from a random image and meanpool over all layers.
                return self.metadata.n_imgs
            case (&#34;patches&#34;, int()):
                # Return a patch from a random image, fixed layer, and random patch.
                return self.metadata.n_imgs * (self.metadata.n_patches_per_img)
            case (&#34;patches&#34;, &#34;meanpool&#34;):
                # Return a patch from a random image, meanpooled over all layers, and a random patch.
                return self.metadata.n_imgs * (self.metadata.n_patches_per_img)
            case (&#34;patches&#34;, &#34;all&#34;):
                # Return a patch from a random image, random layer and random patch.
                return (
                    self.metadata.n_imgs
                    * len(self.metadata.layers)
                    * self.metadata.n_patches_per_img
                )
            case _:
                typing.assert_never((self.cfg.patches, self.cfg.layer))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="saev.activations.Dataset.Example"><code class="name">var <span class="ident">Example</span></code></dt>
<dd>
<div class="desc"><p>Individual example.</p></div>
</dd>
<dt id="saev.activations.Dataset.act_mean"><code class="name">var <span class="ident">act_mean</span> : jaxtyping.Float[Tensor, 'd_vit']</code></dt>
<dd>
<div class="desc"><p>Mean activation.</p></div>
</dd>
<dt id="saev.activations.Dataset.cfg"><code class="name">var <span class="ident">cfg</span> : <a title="saev.config.DataLoad" href="config.html#saev.config.DataLoad">DataLoad</a></code></dt>
<dd>
<div class="desc"><p>Configuration; set via CLI args.</p></div>
</dd>
<dt id="saev.activations.Dataset.layer_index"><code class="name">var <span class="ident">layer_index</span> : int</code></dt>
<dd>
<div class="desc"><p>Layer index into the shards if we are choosing a specific layer.</p></div>
</dd>
<dt id="saev.activations.Dataset.metadata"><code class="name">var <span class="ident">metadata</span> : <a title="saev.activations.Metadata" href="#saev.activations.Metadata">Metadata</a></code></dt>
<dd>
<div class="desc"><p>Activations metadata; automatically loaded from disk.</p></div>
</dd>
<dt id="saev.activations.Dataset.scalar"><code class="name">var <span class="ident">scalar</span> : float</code></dt>
<dd>
<div class="desc"><p>Normalizing scalar such that ||x / scalar ||_2 ~= sqrt(d_vit).</p></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="saev.activations.Dataset.d_vit"><code class="name">prop <span class="ident">d_vit</span> : int</code></dt>
<dd>
<div class="desc"><p>Dimension of the underlying vision transformer's embedding space.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def d_vit(self) -&gt; int:
    &#34;&#34;&#34;Dimension of the underlying vision transformer&#39;s embedding space.&#34;&#34;&#34;
    return self.metadata.d_vit</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="saev.activations.Dataset.get_img_patches"><code class="name flex">
<span>def <span class="ident">get_img_patches</span></span>(<span>self, i: int) ‑> jaxtyping.Float[ndarray, 'n_layers all_patches d_vit']</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Dataset.get_shard_patches"><code class="name flex">
<span>def <span class="ident">get_shard_patches</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Dataset.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self, act: jaxtyping.Float[ndarray, 'd_vit']) ‑> jaxtyping.Float[Tensor, 'd_vit']</span>
</code></dt>
<dd>
<div class="desc"><p>Apply a scalar normalization so the mean squared L2 norm is same as d_vit. This is from 'Scaling Monosemanticity':</p>
<blockquote>
<p>As a preprocessing step we apply a scalar normalization to the model activations so their average squared L2 norm is the residual stream dimension</p>
</blockquote>
<p>So we divide by self.scalar which is the datasets (approximate) L2 mean before normalization divided by sqrt(d_vit).</p></div>
</dd>
</dl>
</dd>
<dt id="saev.activations.DinoV2"><code class="flex name class">
<span>class <span class="ident">DinoV2</span></span>
<span>(</span><span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -&gt; None:
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
class DinoV2(torch.nn.Module):
    def __init__(self, cfg: config.Activations):
        super().__init__()

        assert cfg.model_org == &#34;dinov2&#34;

        self.model = torch.hub.load(&#34;facebookresearch/dinov2&#34;, cfg.model_ckpt)

        n_reg = self.model.num_register_tokens
        patches = torch.cat((
            torch.tensor([0]),  # CLS token
            torch.arange(n_reg + 1, n_reg + 1 + cfg.n_patches_per_img),  # patches
        ))

        self.recorder = VitRecorder(cfg, patches).register(self.model.blocks)

    def make_img_transform(self):
        from torchvision.transforms import v2

        return v2.Compose([
            v2.Resize(size=256),
            v2.CenterCrop(size=(224, 224)),
            v2.ToImage(),
            v2.ToDtype(torch.float32, scale=True),
            v2.Normalize(mean=[0.4850, 0.4560, 0.4060], std=[0.2290, 0.2240, 0.2250]),
        ])

    def forward(self, batch: Float[Tensor, &#34;batch 3 width height&#34;]):
        self.recorder.reset()

        dct = self.model.forward_features(batch)

        features = torch.cat(
            (dct[&#34;x_norm_clstoken&#34;][:, None, :], dct[&#34;x_norm_patchtokens&#34;]), axis=1
        )
        return features, self.recorder.activations</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="saev.activations.DinoV2.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, batch: jaxtyping.Float[Tensor, 'batch 3 width height']) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
</dd>
<dt id="saev.activations.DinoV2.make_img_transform"><code class="name flex">
<span>def <span class="ident">make_img_transform</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="saev.activations.Metadata"><code class="flex name class">
<span>class <span class="ident">Metadata</span></span>
<span>(</span><span>model_org: str, model_ckpt: str, layers: tuple[int, ...], n_patches_per_img: int, cls_token: bool, d_vit: int, seed: int, n_imgs: int, n_patches_per_shard: int, data: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Metadata(model_org: str, model_ckpt: str, layers: tuple[int, &hellip;], n_patches_per_img: int, cls_token: bool, d_vit: int, seed: int, n_imgs: int, n_patches_per_shard: int, data: str)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Metadata:
    model_org: str
    model_ckpt: str
    layers: tuple[int, ...]
    n_patches_per_img: int
    cls_token: bool
    d_vit: int
    seed: int
    n_imgs: int
    n_patches_per_shard: int
    data: str

    @classmethod
    def from_cfg(cls, cfg: config.Activations) -&gt; &#34;Metadata&#34;:
        return cls(
            cfg.model_org,
            cfg.model_ckpt,
            tuple(cfg.layers),
            cfg.n_patches_per_img,
            cfg.cls_token,
            cfg.d_vit,
            cfg.seed,
            cfg.data.n_imgs,
            cfg.n_patches_per_shard,
            str(cfg.data),
        )

    @classmethod
    def load(cls, fpath) -&gt; &#34;Metadata&#34;:
        with open(fpath) as fd:
            dct = json.load(fd)
        dct[&#34;layers&#34;] = tuple(dct.pop(&#34;layers&#34;))
        return cls(**dct)

    def dump(self, fpath):
        with open(fpath, &#34;w&#34;) as fd:
            json.dump(dataclasses.asdict(self), fd, indent=4)

    @property
    def hash(self) -&gt; str:
        cfg_str = json.dumps(dataclasses.asdict(self), sort_keys=True)
        return hashlib.sha256(cfg_str.encode(&#34;utf-8&#34;)).hexdigest()</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="saev.activations.Metadata.cls_token"><code class="name">var <span class="ident">cls_token</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.d_vit"><code class="name">var <span class="ident">d_vit</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.data"><code class="name">var <span class="ident">data</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.layers"><code class="name">var <span class="ident">layers</span> : tuple[int, ...]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.model_ckpt"><code class="name">var <span class="ident">model_ckpt</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.model_org"><code class="name">var <span class="ident">model_org</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.n_imgs"><code class="name">var <span class="ident">n_imgs</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.n_patches_per_img"><code class="name">var <span class="ident">n_patches_per_img</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.n_patches_per_shard"><code class="name">var <span class="ident">n_patches_per_shard</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.seed"><code class="name">var <span class="ident">seed</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="saev.activations.Metadata.from_cfg"><code class="name flex">
<span>def <span class="ident">from_cfg</span></span>(<span>cls, cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>) ‑> <a title="saev.activations.Metadata" href="#saev.activations.Metadata">Metadata</a></span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.Metadata.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>cls, fpath) ‑> <a title="saev.activations.Metadata" href="#saev.activations.Metadata">Metadata</a></span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="saev.activations.Metadata.hash"><code class="name">prop <span class="ident">hash</span> : str</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def hash(self) -&gt; str:
    cfg_str = json.dumps(dataclasses.asdict(self), sort_keys=True)
    return hashlib.sha256(cfg_str.encode(&#34;utf-8&#34;)).hexdigest()</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="saev.activations.Metadata.dump"><code class="name flex">
<span>def <span class="ident">dump</span></span>(<span>self, fpath)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="saev.activations.PreprocessedBroden"><code class="flex name class">
<span>class <span class="ident">PreprocessedBroden</span></span>
<span>(</span><span>cfg: <a title="saev.config.BrodenDataset" href="config.html#saev.config.BrodenDataset">BrodenDataset</a>, transform)</span>
</code></dt>
<dd>
<div class="desc"><p>An abstract class representing a :class:<code><a title="saev.activations.Dataset" href="#saev.activations.Dataset">Dataset</a></code>.</p>
<p>All datasets that represent a map from keys to data samples should subclass
it. All subclasses should overwrite :meth:<code>__getitem__</code>, supporting fetching a
data sample for a given key. Subclasses could also optionally overwrite
:meth:<code>__len__</code>, which is expected to return the size of the dataset by many
:class:<code>~torch.utils.data.Sampler</code> implementations and the default options
of :class:<code>~torch.utils.data.DataLoader</code>. Subclasses could also
optionally implement :meth:<code>__getitems__</code>, for speedup batched samples
loading. This method accepts list of indices of samples of batch and returns
list of samples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>:class:<code>~torch.utils.data.DataLoader</code> by default constructs an index
sampler that yields integral indices.
To make it work with a map-style
dataset with non-integral indices/keys, a custom sampler must be provided.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
class PreprocessedBroden(torch.utils.data.Dataset):
    def __init__(self, cfg: config.BrodenDataset, transform):
        import csv

        self.cfg = cfg
        self.transform = transform

        self.samples = []

        with open(os.path.join(cfg.root, &#34;index.csv&#34;)) as fd:
            for row in csv.DictReader(fd):
                self.samples.append(row[&#34;image&#34;])

    def __getitem__(self, i):
        fpath = os.path.join(self.cfg.root, &#34;images&#34;, self.samples[i])
        with open(fpath, &#34;rb&#34;) as fd:
            img = Image.open(fd).convert(&#34;RGB&#34;)
        img = self.transform(img)
        return {&#34;image&#34;: img, &#34;index&#34;: i}

    def __len__(self) -&gt; int:
        return len(self.samples)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
</dd>
<dt id="saev.activations.PreprocessedImageNet"><code class="flex name class">
<span>class <span class="ident">PreprocessedImageNet</span></span>
<span>(</span><span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>, preprocess)</span>
</code></dt>
<dd>
<div class="desc"><p>An abstract class representing a :class:<code><a title="saev.activations.Dataset" href="#saev.activations.Dataset">Dataset</a></code>.</p>
<p>All datasets that represent a map from keys to data samples should subclass
it. All subclasses should overwrite :meth:<code>__getitem__</code>, supporting fetching a
data sample for a given key. Subclasses could also optionally overwrite
:meth:<code>__len__</code>, which is expected to return the size of the dataset by many
:class:<code>~torch.utils.data.Sampler</code> implementations and the default options
of :class:<code>~torch.utils.data.DataLoader</code>. Subclasses could also
optionally implement :meth:<code>__getitems__</code>, for speedup batched samples
loading. This method accepts list of indices of samples of batch and returns
list of samples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>:class:<code>~torch.utils.data.DataLoader</code> by default constructs an index
sampler that yields integral indices.
To make it work with a map-style
dataset with non-integral indices/keys, a custom sampler must be provided.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PreprocessedImageNet(torch.utils.data.Dataset):
    def __init__(self, cfg: config.Activations, preprocess):
        import datasets

        assert isinstance(cfg.data, config.ImagenetDataset)

        self.hf_dataset = datasets.load_dataset(
            cfg.data.name, split=cfg.data.split, trust_remote_code=True
        )

        self.preprocess = preprocess

    def __getitem__(self, i):
        example = self.hf_dataset[i]
        example[&#34;index&#34;] = i
        example[&#34;image&#34;] = self.preprocess(example[&#34;image&#34;].convert(&#34;RGB&#34;))
        return example

    def __len__(self) -&gt; int:
        return len(self.hf_dataset)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
</dd>
<dt id="saev.activations.ShardWriter"><code class="flex name class">
<span>class <span class="ident">ShardWriter</span></span>
<span>(</span><span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>ShardWriter is a stateful object that handles sharded activation writing to disk.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
class ShardWriter:
    &#34;&#34;&#34;
    ShardWriter is a stateful object that handles sharded activation writing to disk.
    &#34;&#34;&#34;

    root: str
    shape: tuple[int, int, int, int]
    shard: int
    acts_path: str
    acts: Float[np.ndarray, &#34;n_imgs_per_shard n_layers all_patches d_vit&#34;] | None
    filled: int

    def __init__(self, cfg: config.Activations):
        self.logger = logging.getLogger(&#34;shard-writer&#34;)

        self.root = get_acts_dir(cfg)

        n_patches_per_img = cfg.n_patches_per_img
        if cfg.cls_token:
            n_patches_per_img += 1
        self.n_imgs_per_shard = (
            cfg.n_patches_per_shard // len(cfg.layers) // n_patches_per_img
        )
        self.shape = (
            self.n_imgs_per_shard,
            len(cfg.layers),
            n_patches_per_img,
            cfg.d_vit,
        )

        self.shard = -1
        self.acts = None
        self.next_shard()

    @jaxtyped(typechecker=beartype.beartype)
    def __setitem__(
        self, i: slice, val: Float[Tensor, &#34;_ n_layers all_patches d_vit&#34;]
    ) -&gt; None:
        assert i.step is None
        a, b = i.start, i.stop
        assert len(val) == b - a

        offset = self.n_imgs_per_shard * self.shard

        if b &gt;= offset + self.n_imgs_per_shard:
            # We have run out of space in this mmap&#39;ed file. Let&#39;s fill it as much as we can.
            n_fit = offset + self.n_imgs_per_shard - a
            self.acts[a - offset : a - offset + n_fit] = val[:n_fit]
            self.filled = a - offset + n_fit

            self.next_shard()

            # Recursively call __setitem__ in case we need *another* shard
            self[a + n_fit : b] = val[n_fit:]
        else:
            msg = f&#34;0 &lt;= {a} - {offset} &lt;= {offset} + {self.n_imgs_per_shard}&#34;
            assert 0 &lt;= a - offset &lt;= offset + self.n_imgs_per_shard, msg
            msg = f&#34;0 &lt;= {b} - {offset} &lt;= {offset} + {self.n_imgs_per_shard}&#34;
            assert 0 &lt;= b - offset &lt;= offset + self.n_imgs_per_shard, msg
            self.acts[a - offset : b - offset] = val
            self.filled = b - offset

    def flush(self) -&gt; None:
        if self.acts is not None:
            self.acts.flush()

        self.acts = None

    def next_shard(self) -&gt; None:
        self.flush()

        self.shard += 1
        self._count = 0
        self.acts_path = os.path.join(self.root, f&#34;acts{self.shard:06}.bin&#34;)
        self.acts = np.memmap(
            self.acts_path, mode=&#34;w+&#34;, dtype=np.float32, shape=self.shape
        )
        self.filled = 0

        self.logger.info(&#34;Opened shard &#39;%s&#39;.&#34;, self.acts_path)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="saev.activations.ShardWriter.acts"><code class="name">var <span class="ident">acts</span> : jaxtyping.Float[ndarray, 'n_imgs_per_shard n_layers all_patches d_vit'] | None</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.ShardWriter.acts_path"><code class="name">var <span class="ident">acts_path</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.ShardWriter.filled"><code class="name">var <span class="ident">filled</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.ShardWriter.root"><code class="name">var <span class="ident">root</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.ShardWriter.shape"><code class="name">var <span class="ident">shape</span> : tuple[int, int, int, int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.ShardWriter.shard"><code class="name">var <span class="ident">shard</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="saev.activations.ShardWriter.flush"><code class="name flex">
<span>def <span class="ident">flush</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.ShardWriter.next_shard"><code class="name flex">
<span>def <span class="ident">next_shard</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="saev.activations.Siglip"><code class="flex name class">
<span>class <span class="ident">Siglip</span></span>
<span>(</span><span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -&gt; None:
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
class Siglip(torch.nn.Module):
    def __init__(self, cfg: config.Activations):
        super().__init__()
        assert cfg.model_org == &#34;siglip&#34;

        import open_clip

        if cfg.model_ckpt.startswith(&#34;hf-hub:&#34;):
            clip, self._img_transform = open_clip.create_model_from_pretrained(
                cfg.model_ckpt, cache_dir=helpers.get_cache_dir()
            )
        else:
            arch, ckpt = cfg.model_ckpt.split(&#34;/&#34;)
            clip, self._img_transform = open_clip.create_model_from_pretrained(
                arch, pretrained=ckpt, cache_dir=helpers.get_cache_dir()
            )

        model = clip.visual
        model.proj = None
        model.output_tokens = True  # type: ignore
        self.model = model

        assert isinstance(self.model, open_clip.timm_model.TimmModel)
        self.recorder = VitRecorder(cfg).register(self.model.trunk.blocks)

    def make_img_transform(self):
        return self._img_transform

    def forward(self, batch: Float[Tensor, &#34;batch 3 width height&#34;]):
        self.recorder.reset()
        result = self.model(batch)
        return result, self.recorder.activations</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="saev.activations.Siglip.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, batch: jaxtyping.Float[Tensor, 'batch 3 width height']) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
</dd>
<dt id="saev.activations.Siglip.make_img_transform"><code class="name flex">
<span>def <span class="ident">make_img_transform</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="saev.activations.TimmVit"><code class="flex name class">
<span>class <span class="ident">TimmVit</span></span>
<span>(</span><span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -&gt; None:
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
class TimmVit(torch.nn.Module):
    def __init__(self, cfg: config.Activations):
        super().__init__()
        assert cfg.model_org == &#34;timm&#34;
        import timm

        err_msg = &#34;You are trying to load a non-ViT checkpoint; the `img_encode()` method assumes `model.forward_features()` will return features with shape (batch, n_patches, dim) which is not true for non-ViT checkpoints.&#34;
        assert &#34;vit&#34; in cfg.model_ckpt, err_msg
        self.model = timm.create_model(cfg.model_ckpt, pretrained=True)

        data_cfg = timm.data.resolve_data_config(self.model.pretrained_cfg)
        self._img_transform = timm.data.create_transform(**data_cfg, is_training=False)

        self.recorder = VitRecorder(cfg).register(self.model.blocks)

    def make_img_transform(self):
        return self._img_transform

    def forward(self, batch: Float[Tensor, &#34;batch 3 width height&#34;]):
        self.recorder.reset()

        patches = self.model.forward_features(batch)
        # Use [CLS] token if it exists for img representation, otherwise do a maxpool
        if self.model.num_prefix_tokens &gt; 0:
            img = patches[:, 0, ...]
        else:
            img = patches.max(axis=1).values

        # Return only the [CLS] token and the patches.
        patches = patches[:, self.model.num_prefix_tokens :, ...]

        return torch.cat((img[:, None, :], patches), axis=1), self.recorder.activations</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="saev.activations.TimmVit.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, batch: jaxtyping.Float[Tensor, 'batch 3 width height']) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
</dd>
<dt id="saev.activations.TimmVit.make_img_transform"><code class="name flex">
<span>def <span class="ident">make_img_transform</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="saev.activations.TransformedImageFolder"><code class="flex name class">
<span>class <span class="ident">TransformedImageFolder</span></span>
<span>(</span><span>root: Union[str, pathlib.Path], transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = &lt;function default_loader&gt;, is_valid_file: Optional[Callable[[str], bool]] = None, allow_empty: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>A generic data loader where the images are arranged in this way by default: ::</p>
<pre><code>root/dog/xxx.png
root/dog/xxy.png
root/dog/[...]/xxz.png

root/cat/123.png
root/cat/nsdf3.png
root/cat/[...]/asd932_.png
</code></pre>
<p>This class inherits from :class:<code>~torchvision.datasets.DatasetFolder</code> so
the same methods can be overridden to customize the dataset.</p>
<h2 id="args">Args</h2>
<dl>
<dt>root (str or <code>pathlib.Path</code>): Root directory path.</dt>
<dt><strong><code>transform</code></strong> :&ensp;<code>callable</code>, optional</dt>
<dd>A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code>transforms.RandomCrop</code></dd>
<dt><strong><code>target_transform</code></strong> :&ensp;<code>callable</code>, optional</dt>
<dd>A function/transform that takes in the
target and transforms it.</dd>
<dt><strong><code>loader</code></strong> :&ensp;<code>callable</code>, optional</dt>
<dd>A function to load an image given its path.</dd>
<dt><strong><code>is_valid_file</code></strong> :&ensp;<code>callable</code>, optional</dt>
<dd>A function that takes path of an Image file
and check if the file is a valid file (used to check of corrupt files)</dd>
</dl>
<p>allow_empty(bool, optional): If True, empty folders are considered to be valid classes.
An error is raised on empty folders if False (default).
Attributes:
classes (list): List of the class names sorted alphabetically.
class_to_idx (dict): Dict with items (class_name, class_index).
imgs (list): List of (image path, class_index) tuples</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TransformedImageFolder(torchvision.datasets.ImageFolder):
    def __getitem__(self, index: int) -&gt; dict[str, object]:
        &#34;&#34;&#34;
        Args:
            index: Index

        Returns:
            dict with keys &#39;image&#39;, &#39;index&#39;, &#39;target&#39; and &#39;label&#39;.
        &#34;&#34;&#34;
        breakpoint()
        path, target = self.samples[index]
        sample = self.loader(path)
        if self.transform is not None:
            sample = self.transform(sample)
        if self.target_transform is not None:
            target = self.target_transform(target)

        return {&#34;image&#34;: sample, &#34;target&#34;: target, &#34;index&#34;: index}</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torchvision.datasets.folder.ImageFolder</li>
<li>torchvision.datasets.folder.DatasetFolder</li>
<li>torchvision.datasets.vision.VisionDataset</li>
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
</dd>
<dt id="saev.activations.VitRecorder"><code class="flex name class">
<span>class <span class="ident">VitRecorder</span></span>
<span>(</span><span>cfg: <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a>, patches: slice = slice(None, None, None))</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -&gt; None:
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
class VitRecorder(torch.nn.Module):
    cfg: config.Activations
    _storage: Float[Tensor, &#34;batch n_layers all_patches dim&#34;] | None
    _i: int

    def __init__(
        self, cfg: config.Activations, patches: slice = slice(None, None, None)
    ):
        super().__init__()

        self.cfg = cfg
        self.patches = patches
        self._storage = None
        self._i = 0
        self.logger = logging.getLogger(f&#34;recorder({cfg.model_org}:{cfg.model_ckpt})&#34;)

    def register(self, modules: list[torch.nn.Module]):
        for i in self.cfg.layers:
            modules[i].register_forward_hook(self.hook)
        return self

    def hook(
        self, module, args: tuple, output: Float[Tensor, &#34;batch n_layers dim&#34;]
    ) -&gt; None:
        if self._storage is None:
            batch, _, dim = output.shape
            self._storage = self._empty_storage(batch, dim, output.device)

        if self._storage[:, self._i, 0, :].shape != output[:, 0, :].shape:
            batch, _, dim = output.shape

            old_batch, _, _, old_dim = self._storage.shape
            msg = &#34;Output shape does not match storage shape: (batch) %d != %d or (dim) %d != %d&#34;
            self.logger.warning(msg, old_batch, batch, old_dim, dim)

            self._storage = self._empty_storage(batch, dim, output.device)

        self._storage[:, self._i] = output[:, self.patches, :].detach()
        self._i += 1

    def _empty_storage(self, batch: int, dim: int, device: torch.device):
        n_patches_per_img = self.cfg.n_patches_per_img
        if self.cfg.cls_token:
            n_patches_per_img += 1

        return torch.zeros(
            (batch, len(self.cfg.layers), n_patches_per_img, dim), device=device
        )

    def reset(self):
        self._i = 0

    @property
    def activations(self) -&gt; Float[Tensor, &#34;batch n_layers all_patches dim&#34;]:
        if self._storage is None:
            raise RuntimeError(&#34;First call model()&#34;)
        return self._storage.cpu()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="saev.activations.VitRecorder.cfg"><code class="name">var <span class="ident">cfg</span> : <a title="saev.config.Activations" href="config.html#saev.config.Activations">Activations</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="saev.activations.VitRecorder.activations"><code class="name">prop <span class="ident">activations</span> : jaxtyping.Float[Tensor, 'batch n_layers all_patches dim']</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def activations(self) -&gt; Float[Tensor, &#34;batch n_layers all_patches dim&#34;]:
    if self._storage is None:
        raise RuntimeError(&#34;First call model()&#34;)
    return self._storage.cpu()</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="saev.activations.VitRecorder.hook"><code class="name flex">
<span>def <span class="ident">hook</span></span>(<span>self, module, args: tuple, output: jaxtyping.Float[Tensor, 'batch n_layers dim']) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.VitRecorder.register"><code class="name flex">
<span>def <span class="ident">register</span></span>(<span>self, modules: list[torch.nn.modules.module.Module])</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="saev.activations.VitRecorder.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="saev" href="index.html">saev</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="saev.activations.dump" href="#saev.activations.dump">dump</a></code></li>
<li><code><a title="saev.activations.get_acts_dir" href="#saev.activations.get_acts_dir">get_acts_dir</a></code></li>
<li><code><a title="saev.activations.get_broden_dataloader" href="#saev.activations.get_broden_dataloader">get_broden_dataloader</a></code></li>
<li><code><a title="saev.activations.get_dataloader" href="#saev.activations.get_dataloader">get_dataloader</a></code></li>
<li><code><a title="saev.activations.get_imagefolder_dataloader" href="#saev.activations.get_imagefolder_dataloader">get_imagefolder_dataloader</a></code></li>
<li><code><a title="saev.activations.get_imagenet_dataloader" href="#saev.activations.get_imagenet_dataloader">get_imagenet_dataloader</a></code></li>
<li><code><a title="saev.activations.get_laion_dataloader" href="#saev.activations.get_laion_dataloader">get_laion_dataloader</a></code></li>
<li><code><a title="saev.activations.get_tol_dataloader" href="#saev.activations.get_tol_dataloader">get_tol_dataloader</a></code></li>
<li><code><a title="saev.activations.make_vit" href="#saev.activations.make_vit">make_vit</a></code></li>
<li><code><a title="saev.activations.setup" href="#saev.activations.setup">setup</a></code></li>
<li><code><a title="saev.activations.setup_broden" href="#saev.activations.setup_broden">setup_broden</a></code></li>
<li><code><a title="saev.activations.setup_imagefolder" href="#saev.activations.setup_imagefolder">setup_imagefolder</a></code></li>
<li><code><a title="saev.activations.setup_imagenet" href="#saev.activations.setup_imagenet">setup_imagenet</a></code></li>
<li><code><a title="saev.activations.setup_laion" href="#saev.activations.setup_laion">setup_laion</a></code></li>
<li><code><a title="saev.activations.setup_tol" href="#saev.activations.setup_tol">setup_tol</a></code></li>
<li><code><a title="saev.activations.worker_fn" href="#saev.activations.worker_fn">worker_fn</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="saev.activations.Clip" href="#saev.activations.Clip">Clip</a></code></h4>
<ul class="">
<li><code><a title="saev.activations.Clip.forward" href="#saev.activations.Clip.forward">forward</a></code></li>
<li><code><a title="saev.activations.Clip.make_img_transform" href="#saev.activations.Clip.make_img_transform">make_img_transform</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="saev.activations.Dataset" href="#saev.activations.Dataset">Dataset</a></code></h4>
<ul class="two-column">
<li><code><a title="saev.activations.Dataset.Example" href="#saev.activations.Dataset.Example">Example</a></code></li>
<li><code><a title="saev.activations.Dataset.act_mean" href="#saev.activations.Dataset.act_mean">act_mean</a></code></li>
<li><code><a title="saev.activations.Dataset.cfg" href="#saev.activations.Dataset.cfg">cfg</a></code></li>
<li><code><a title="saev.activations.Dataset.d_vit" href="#saev.activations.Dataset.d_vit">d_vit</a></code></li>
<li><code><a title="saev.activations.Dataset.get_img_patches" href="#saev.activations.Dataset.get_img_patches">get_img_patches</a></code></li>
<li><code><a title="saev.activations.Dataset.get_shard_patches" href="#saev.activations.Dataset.get_shard_patches">get_shard_patches</a></code></li>
<li><code><a title="saev.activations.Dataset.layer_index" href="#saev.activations.Dataset.layer_index">layer_index</a></code></li>
<li><code><a title="saev.activations.Dataset.metadata" href="#saev.activations.Dataset.metadata">metadata</a></code></li>
<li><code><a title="saev.activations.Dataset.scalar" href="#saev.activations.Dataset.scalar">scalar</a></code></li>
<li><code><a title="saev.activations.Dataset.transform" href="#saev.activations.Dataset.transform">transform</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="saev.activations.DinoV2" href="#saev.activations.DinoV2">DinoV2</a></code></h4>
<ul class="">
<li><code><a title="saev.activations.DinoV2.forward" href="#saev.activations.DinoV2.forward">forward</a></code></li>
<li><code><a title="saev.activations.DinoV2.make_img_transform" href="#saev.activations.DinoV2.make_img_transform">make_img_transform</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="saev.activations.Metadata" href="#saev.activations.Metadata">Metadata</a></code></h4>
<ul class="two-column">
<li><code><a title="saev.activations.Metadata.cls_token" href="#saev.activations.Metadata.cls_token">cls_token</a></code></li>
<li><code><a title="saev.activations.Metadata.d_vit" href="#saev.activations.Metadata.d_vit">d_vit</a></code></li>
<li><code><a title="saev.activations.Metadata.data" href="#saev.activations.Metadata.data">data</a></code></li>
<li><code><a title="saev.activations.Metadata.dump" href="#saev.activations.Metadata.dump">dump</a></code></li>
<li><code><a title="saev.activations.Metadata.from_cfg" href="#saev.activations.Metadata.from_cfg">from_cfg</a></code></li>
<li><code><a title="saev.activations.Metadata.hash" href="#saev.activations.Metadata.hash">hash</a></code></li>
<li><code><a title="saev.activations.Metadata.layers" href="#saev.activations.Metadata.layers">layers</a></code></li>
<li><code><a title="saev.activations.Metadata.load" href="#saev.activations.Metadata.load">load</a></code></li>
<li><code><a title="saev.activations.Metadata.model_ckpt" href="#saev.activations.Metadata.model_ckpt">model_ckpt</a></code></li>
<li><code><a title="saev.activations.Metadata.model_org" href="#saev.activations.Metadata.model_org">model_org</a></code></li>
<li><code><a title="saev.activations.Metadata.n_imgs" href="#saev.activations.Metadata.n_imgs">n_imgs</a></code></li>
<li><code><a title="saev.activations.Metadata.n_patches_per_img" href="#saev.activations.Metadata.n_patches_per_img">n_patches_per_img</a></code></li>
<li><code><a title="saev.activations.Metadata.n_patches_per_shard" href="#saev.activations.Metadata.n_patches_per_shard">n_patches_per_shard</a></code></li>
<li><code><a title="saev.activations.Metadata.seed" href="#saev.activations.Metadata.seed">seed</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="saev.activations.PreprocessedBroden" href="#saev.activations.PreprocessedBroden">PreprocessedBroden</a></code></h4>
</li>
<li>
<h4><code><a title="saev.activations.PreprocessedImageNet" href="#saev.activations.PreprocessedImageNet">PreprocessedImageNet</a></code></h4>
</li>
<li>
<h4><code><a title="saev.activations.ShardWriter" href="#saev.activations.ShardWriter">ShardWriter</a></code></h4>
<ul class="two-column">
<li><code><a title="saev.activations.ShardWriter.acts" href="#saev.activations.ShardWriter.acts">acts</a></code></li>
<li><code><a title="saev.activations.ShardWriter.acts_path" href="#saev.activations.ShardWriter.acts_path">acts_path</a></code></li>
<li><code><a title="saev.activations.ShardWriter.filled" href="#saev.activations.ShardWriter.filled">filled</a></code></li>
<li><code><a title="saev.activations.ShardWriter.flush" href="#saev.activations.ShardWriter.flush">flush</a></code></li>
<li><code><a title="saev.activations.ShardWriter.next_shard" href="#saev.activations.ShardWriter.next_shard">next_shard</a></code></li>
<li><code><a title="saev.activations.ShardWriter.root" href="#saev.activations.ShardWriter.root">root</a></code></li>
<li><code><a title="saev.activations.ShardWriter.shape" href="#saev.activations.ShardWriter.shape">shape</a></code></li>
<li><code><a title="saev.activations.ShardWriter.shard" href="#saev.activations.ShardWriter.shard">shard</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="saev.activations.Siglip" href="#saev.activations.Siglip">Siglip</a></code></h4>
<ul class="">
<li><code><a title="saev.activations.Siglip.forward" href="#saev.activations.Siglip.forward">forward</a></code></li>
<li><code><a title="saev.activations.Siglip.make_img_transform" href="#saev.activations.Siglip.make_img_transform">make_img_transform</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="saev.activations.TimmVit" href="#saev.activations.TimmVit">TimmVit</a></code></h4>
<ul class="">
<li><code><a title="saev.activations.TimmVit.forward" href="#saev.activations.TimmVit.forward">forward</a></code></li>
<li><code><a title="saev.activations.TimmVit.make_img_transform" href="#saev.activations.TimmVit.make_img_transform">make_img_transform</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="saev.activations.TransformedImageFolder" href="#saev.activations.TransformedImageFolder">TransformedImageFolder</a></code></h4>
</li>
<li>
<h4><code><a title="saev.activations.VitRecorder" href="#saev.activations.VitRecorder">VitRecorder</a></code></h4>
<ul class="">
<li><code><a title="saev.activations.VitRecorder.activations" href="#saev.activations.VitRecorder.activations">activations</a></code></li>
<li><code><a title="saev.activations.VitRecorder.cfg" href="#saev.activations.VitRecorder.cfg">cfg</a></code></li>
<li><code><a title="saev.activations.VitRecorder.hook" href="#saev.activations.VitRecorder.hook">hook</a></code></li>
<li><code><a title="saev.activations.VitRecorder.register" href="#saev.activations.VitRecorder.register">register</a></code></li>
<li><code><a title="saev.activations.VitRecorder.reset" href="#saev.activations.VitRecorder.reset">reset</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>
